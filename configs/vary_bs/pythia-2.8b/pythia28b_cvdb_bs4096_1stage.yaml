data_arguments:
  dataset: "cvdb"
  block_size: 48
  label_block_size: 8
  train_subset: 'full'
  num_ents: 4000

  frac_n_qd1consis: 0.25
  frac_n_qd1incons: 0.0
  frac_n_qd2consis: 0.0
  frac_n_qd2incons: 0.25
  frac_n_q_no_replacement_baseline: 0.1
  frac_n_q: 0.1
  frac_n_d1consis: 0.1
  frac_n_d2consis: 0.1
  frac_n_d3consis: 0.0
  frac_n_no_qd_baseline: 0.1


model_arguments:
  seq2seq: False
  max_new_tokens: 8
  # model_name_or_path: "EleutherAI/pythia-410m-deduped"
  # model_name_or_path: "EleutherAI/pythia-160m-deduped"
  model_name_or_path: "EleutherAI/pythia-2.8b-deduped"
  # model_name_or_path: "EleutherAI/pythia-1b-deduped"


training_arguments:
  output_dir: 'experiments/temp'
  bf16: True
  per_device_train_batch_size: 128
  per_device_eval_batch_size: 128
  optim: "adafactor"
  overwrite_output_dir: True
  auto_find_batch_size: True
  save_strategy: "no"
  load_best_model_at_end: False
  evaluation_strategy: 'epoch'

  do_train: True
  do_sweeps: False
  save_each_epochs: 0
  eval_each_epochs: 12
  eval_callback_type: "pipeline"  # pipeline or generate

experiment_arguments: # common experiment arguments
  define_experiment: True
  numeric_experiment: False
  name_prefix: "entAttr_bs4096"
  n_stages: 1
  n_seeds: 5
  n_seeds_stage2: 3
  start_seed: 600
  slurm: True
  n_gpu_hours: 32


define_experiment_arguments:
  def_order: "tve"
  entity_association_test_sets: True
  

numeric_experiment_arguments:
  modular_experiment_baseline: False
  modular_experiment: False
  num_choice_experiment: False


# overrides specified parameters
first_stage_arguments:
  do_eval: False  # This is only evals of losses, not generation callbacks
  train_subset: 'full'
  num_train_epochs: 61
  gradient_accumulation_steps: 32
  dont_save_in_the_end: True